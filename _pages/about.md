---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- css -->
<link rel="stylesheet" type="text/css" href="/assets/css/paper.css">

<!-- self intro -->
### Bios
My name is Hongchi Xia (夏鸿驰). 
I'm now a second-year Ph.D. student at Computer Science at University of Illinois Urbana-Champaign (UIUC), 
where I collaborate with <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> and <a href="https://www.cs.cornell.edu/~weichiu/">Wei-Chiu Ma</a>.
<br>
<br>
My research lies in 3D computer vision, building essential foundations for spatial intelligence. Previously, I conducted a series of works related to 3D reconstruction and photorealistic re-simulation with grounded physics. Recently, I've gone into 3D generation approach, aiming at addressing the urgent need of rich and diverse 3D data.
<br>
<br>
I received my bachelor's degree at Shanghai Jiao Tong University (SJTU), and I was fortunate to have research internships advised by <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> at UIUC, <a href="https://www.cs.cornell.edu/~weichiu/">Wei-Chiu Ma</a> at Cornell, <a href="https://xiaolonw.github.io/">Xiaolong Wang</a> at UCSD and <a href="https://www.mvig.org/">Cewu Lu</a> at SJTU. I was a research intern at <a href="https://research.nvidia.com/labs/dir/">NVIDIA Deep Imagination Research</a> during Summer 2025, where I mainly collaborated with <a href="https://weify627.github.io/">Fangyin Wei</a>.
<br>
<br>
Check my Curriculum Vitae <a href="./files/CV_2025_10.pdf">Here</a>.
<br>


### News
* <b>Feb.2026</b> Our new agentic scene generation project "SAGE" is released!
* <b>Oct.2025</b> "HoloScene" is accepted to NeurIPS 2025! See you in San Diego!
* <b>May.2025</b> Had my first summer internship at NVIDIA.
* <b>Apr.2025</b> "DRAWER" is accepted to CVPR 2025! See you in Nashville!
* <b>Aug.2024</b> Start the PhD journey at UIUC!
* <b>Feb.2024</b> Two papers "Video2Game" and "WildRGB-D" are accepted to CVPR 2024!

### Selected Publications [<a href="https://scholar.google.com/citations?user=9iXQ-wsAAAAJ&hl=en">ALL</a>]

<!-- paper start -->
<div class="paper">

<div class="pimg"> 
<img src="/images/sage.gif" width="200" height="140">
</div>

<div class="ptitle">SAGE: Scalable Agentic 3D Scene Generation for Embodied AI</div>

<div class="pauthors"> <b>Hongchi Xia</b>, Xuan Li, Zhaoshuo Li, Qianli Ma, Jiashu Xu, Ming-Yu Liu, Yin Cui, Tsung-Yi Lin, Wei-Chiu Ma, Shenlong Wang, Shuran Song, Fangyin Wei</div>

<div class="pvenue">
<p>Arxiv</p>
<p>[<a href="https://nvlabs.github.io/sage/">project</a>] [<a href="">paper</a>] [<a href="https://github.com/NVlabs/sage">code</a>] [<a href="https://huggingface.co/datasets/nvidia/SAGE-10k">dataset</a>]</p>
</div>


</div>
<!-- paper end -->


<!-- paper start -->
<div class="paper">

<div class="pimg"> 
<img src="/images/holoscene.gif" width="200" height="140">
</div>

<div class="ptitle">HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video</div>

<div class="pauthors"> <b>Hongchi Xia</b>, Chih-Hao Lin, Hao-Yu Hsu, Quentin Leboutet, Katelyn Gao, Michael Paulitsch, Benjamin Ummenhofer, Shenlong Wang</div>

<div class="pvenue">
<p>Neural Information Processing Systems (NeurIPS), 2025</p>
<p>[<a href="https://xiahongchi.github.io/HoloScene/">project</a>] [<a href="https://arxiv.org/pdf/2510.05560">paper</a>] [<a href="https://github.com/xiahongchi/HoloScene">code</a>]</p>
</div>


</div>
<!-- paper end -->

<!-- paper start -->
<div class="paper">

<div class="pimg"> 
<img src="/images/drawer.gif" width="200" height="140">
</div>

<div class="ptitle">DRAWER: Digital Reconstruction and Articulation With Environment Realism</div>

<div class="pauthors"> <b>Hongchi Xia</b>, Entong Su, Marius Memmel, Arhan Jain, Raymond Yu, Numfor Mbiziwo-Tiapo, Ali Farhadi, Abhishek Gupta, Shenlong Wang, Wei-Chiu Ma</div>

<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
<p>[<a href="https://drawer-art.github.io/">project</a>] [<a href="https://arxiv.org/abs/2504.15278">paper</a>] [<a href="https://github.com/xiahongchi/DRAWER">code</a>]</p>
</div>


</div>
<!-- paper end -->


<!-- paper start -->
<div class="paper">

<div class="pimg"> 
<img src="/images/garden.png" width="200" height="140">
</div>

<div class="ptitle">Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video</div>

<div class="pauthors"> <b>Hongchi Xia</b>, Zhi-Hao Lin, Wei-Chiu Ma, Shenlong Wang</div>

<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>
<p>[<a href="https://video2game.github.io/">project</a>] [<a href="https://arxiv.org/abs/2404.09833">paper</a>] [<a href="https://github.com/video2game/video2game">code</a>]</p>
</div>

</div>
<!-- paper end -->


<!-- paper start -->
<div class="paper">

<div class="pimg"> 
<img class="media-object img-rounded img-responsive" src="/images/pineapple.avifs" width="200" height="140">
</div>

<div class="ptitle">RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from RGB-D Videos</div>

<div class="pauthors"> <b>Hongchi Xia</b>*, Yang Fu*, Sifei Liu, Xiaolong Wang </div>

<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>
<p>[<a href="https://wildrgbd.github.io/">project</a>] [<a href="https://arxiv.org/abs/2401.12592">paper</a>] [<a href="https://github.com/wildrgbd/wildrgbd">code</a>]</p>
</div>

</div>
<!-- paper end -->